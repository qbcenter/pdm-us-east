{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特徵工程\n",
    "\n",
    "在機器學習中，一個「特徵」指的是一個「被觀察的現象之可測量屬性」，而該觀測現象之所有特徵的集合又稱為該現象的「表徵」。\n",
    "從原始資料中抽取特徵的過程稱之為「特徵工程」。特徵工程的目的，是為了從原始資料中，轉換出適合機器學習算法的表徵。\n",
    "\n",
    "特徵工程通常需要一定程度的領域知識，並可分為下列階段 [[1]]($ref_1)：\n",
    "1. 思考可能的特徵\n",
    "2. 決定該抽取哪些特徵\n",
    "3. 抽取特徵\n",
    "4. 研究特徵如何影響模型的預測能力\n",
    "5. 重複 1~4 直到模型可以被接受"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>1</td><td>application_1545316055964_0002</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-10-0-0-92.us-east-2.compute.internal:20888/proxy/application_1545316055964_0002/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-10-0-0-162.us-east-2.compute.internal:8042/node/containerlogs/container_1545316055964_0002_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from functools import reduce\n",
    "from pyspark.sql import SparkSession, SQLContext, Window\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "請使用自己的 S3 存貯體：`s3a://<YOUR_BUCKET>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root_dir = 's3a://pdm-sagemaker-dac43ec6047111e995b9d4619d3b01d6'\n",
    "telemetry_dir = data_root_dir + '/static/telemetry'\n",
    "input_logs_dir = data_root_dir + '/static/logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('agg',warn=False, force=True)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讀取資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- ambient_pressure: double (nullable = true)\n",
      " |-- ambient_temperature: double (nullable = true)\n",
      " |-- machineID: string (nullable = true)\n",
      " |-- pressure: double (nullable = true)\n",
      " |-- speed: double (nullable = true)\n",
      " |-- speed_desired: long (nullable = true)\n",
      " |-- temperature: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- code: string (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- machineID: string (nullable = true)\n",
      "\n",
      "Total:\n",
      "\n",
      "  13043552 telemetry entries\n",
      "       537 log entries"
     ]
    }
   ],
   "source": [
    "sc = SparkSession.builder.getOrCreate()\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "telemetry_input_df = sqlContext.read.parquet(telemetry_dir)\n",
    "logs_input_df = sqlContext.read.parquet(input_logs_dir)\n",
    "\n",
    "telemetry_input_df.printSchema()\n",
    "logs_input_df.printSchema()\n",
    "\n",
    "telemetry_entries_count = telemetry_input_df.count()\n",
    "log_entries_count = logs_input_df.count()\n",
    "\n",
    "print('Total:\\n\\n{0:10d} telemetry entries\\n{1:10d} log entries'.format(\n",
    "    telemetry_entries_count, log_entries_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 資料探索\n",
    "\n",
    "讓我們先回答幾個關於資料集的基本問題\n",
    "\n",
    "### Q: 有多少不同的機器產生了遙測資料？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 machine(s)"
     ]
    }
   ],
   "source": [
    "distinct_machines_df = telemetry_input_df.select('machineID').distinct()\n",
    "machine_count = distinct_machines_df.count()\n",
    "print('{0} machine(s)'.format(machine_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: 遙測資料橫跨了多長的時間區段？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+---------------+\n",
      "|              start|                end|duration (days)|\n",
      "+-------------------+-------------------+---------------+\n",
      "|2017-05-15 00:02:00|2017-08-14 22:57:59|             91|\n",
      "+-------------------+-------------------+---------------+"
     ]
    }
   ],
   "source": [
    "telemetry_input_df.select(\n",
    "    F.min('timestamp').alias('start'), F.max('timestamp').alias('end')\n",
    ").withColumn(\n",
    "    'duration (days)',\n",
    "    F.datediff(F.col('end'), F.col('start'))\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: 共有哪些類型的日誌事件？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+\n",
      "|   level|count(level)|\n",
      "+--------+------------+\n",
      "|    INFO|         265|\n",
      "|CRITICAL|         272|\n",
      "+--------+------------+"
     ]
    }
   ],
   "source": [
    "logs_input_df.select('level').groupBy('level').agg(\n",
    "    F.count('level')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "日誌事件類型遵循下列規範：\n",
    "\n",
    "* **INFO**: \n",
    "非錯誤的紀錄。除此之外，也包含關於排程/非排程的修復程序。\n",
    "* **WARNING**: \n",
    "非嚴重，但可能有危害，或異常的狀況。\n",
    "* **CRITICAL**:\n",
    "不可回復的狀況，需要額外干預（修補）。\n",
    "\n",
    "### Q: 什麼類型的 CRITICAL 事件（故障）被記錄在日誌中？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  code  count\n",
      "0   F2     77\n",
      "1   F1    195"
     ]
    }
   ],
   "source": [
    "failures_df = logs_input_df.where(F.col('level') == 'CRITICAL')\n",
    "\n",
    "failures_df.select('code').groupBy('code').agg(\n",
    "    F.count(F.lit(1)).alias('count')\n",
    ").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: 每部機台發生多少次故障？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               # Of Machines\n",
      "Failure Count               \n",
      "0                        734\n",
      "1                        260\n",
      "2                          6"
     ]
    }
   ],
   "source": [
    "machine_failures_df = distinct_machines_df.join(\n",
    "    failures_df, 'machineID', 'left_outer'\n",
    ").groupBy('machineID').agg(F.count('code').alias('count'))\n",
    "\n",
    "mf_pandas = machine_failures_df.toPandas()\n",
    "mf_pandas.columns = ['# Of Machines', 'Failure Count']\n",
    "mf_pandas.groupby('Failure Count').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: 單一機台的原始資料流有哪些特性？\n",
    "#### 敘述統計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive statistics of \"faulty\" machine M_0776\n",
      "       ambient_pressure      ...        temperature\n",
      "count      13420.000000      ...       13420.000000\n",
      "mean         100.999055      ...         141.870811\n",
      "std            0.058138      ...           6.758752\n",
      "min          100.900000      ...          24.520000\n",
      "25%          100.950000      ...         135.720000\n",
      "50%          101.000000      ...         138.190000\n",
      "75%          101.050000      ...         147.800000\n",
      "max          101.100000      ...         154.400000\n",
      "\n",
      "[8 rows x 6 columns]"
     ]
    }
   ],
   "source": [
    "# get ID of one of the most \"faulty\" machines\n",
    "faultyMachineID = machine_failures_df.orderBy(F.desc('count')).first().machineID\n",
    "\n",
    "faulty_machine_sequence_df = telemetry_input_df.where(\n",
    "    telemetry_input_df.machineID == faultyMachineID\n",
    ").orderBy(telemetry_input_df.timestamp)\n",
    "\n",
    "faulty_machine_sequence_pdf = faulty_machine_sequence_df.toPandas()\n",
    "faulty_machine_sequence_pdf.set_index('timestamp', inplace=True)\n",
    "print('Descriptive statistics of \"faulty\" machine {}'.format(faultyMachineID))\n",
    "faulty_machine_sequence_pdf.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "為了比較，這裡列出 **健康** 機台的敘述統計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive statistics of \"healthy\" machine M_0830\n",
      "       ambient_pressure      ...        temperature\n",
      "count      12349.000000      ...       12349.000000\n",
      "mean         101.000020      ...         137.494886\n",
      "std            0.058062      ...           2.709765\n",
      "min          100.900000      ...          23.060000\n",
      "25%          100.950000      ...         136.980000\n",
      "50%          101.000000      ...         137.520000\n",
      "75%          101.050000      ...         138.140000\n",
      "max          101.100000      ...         138.940000\n",
      "\n",
      "[8 rows x 6 columns]"
     ]
    }
   ],
   "source": [
    "# get ID of one of the \"healthy\" machines\n",
    "healthyMachineID = machine_failures_df.orderBy(F.asc('count')).first().machineID\n",
    "\n",
    "healthy_machine_sequence_df = telemetry_input_df.where(\n",
    "    telemetry_input_df.machineID == healthyMachineID\n",
    ").orderBy(telemetry_input_df.timestamp)\n",
    "\n",
    "healthy_machine_sequence_pdf = healthy_machine_sequence_df.toPandas()\n",
    "healthy_machine_sequence_pdf.set_index('timestamp', inplace=True)\n",
    "print('Descriptive statistics of \"healthy\" machine {}'.format(healthyMachineID))\n",
    "healthy_machine_sequence_pdf.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 時間特性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sample of \"faulty\" machine M_0776\n",
      "                     ambient_pressure     ...       temperature\n",
      "timestamp                                 ...                  \n",
      "2017-05-15 10:10:00            100.93     ...             24.52\n",
      "2017-05-15 10:10:01            100.97     ...             30.35\n",
      "2017-05-15 10:10:02            100.97     ...             37.67\n",
      "2017-05-15 10:10:03            101.10     ...             46.72\n",
      "2017-05-15 10:10:04            101.00     ...             57.49\n",
      "\n",
      "[5 rows x 7 columns]"
     ]
    }
   ],
   "source": [
    "# Data sample\n",
    "print('Data sample of \"faulty\" machine {}'.format(faultyMachineID))\n",
    "faulty_machine_sequence_pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp\n",
      "2017-05-15 10:10:00    1\n",
      "2017-05-15 10:10:01    1\n",
      "2017-05-15 10:10:02    1\n",
      "2017-05-15 10:10:03    1\n",
      "2017-05-15 10:10:04    1\n",
      "2017-05-15 10:10:05    1\n",
      "2017-05-15 10:10:06    1\n",
      "2017-05-15 10:10:07    1\n",
      "2017-05-15 10:10:08    1\n",
      "2017-05-15 10:10:09    1\n",
      "2017-05-15 10:10:10    1\n",
      "2017-05-15 10:10:11    1\n",
      "2017-05-15 10:10:12    1\n",
      "2017-05-15 10:10:13    1\n",
      "2017-05-15 10:10:14    1\n",
      "2017-05-15 10:10:15    1\n",
      "2017-05-15 10:10:16    1\n",
      "2017-05-15 10:10:17    1\n",
      "2017-05-15 10:10:18    1\n",
      "2017-05-15 10:10:19    1\n",
      "2017-05-15 10:10:20    1\n",
      "2017-05-15 10:10:21    1\n",
      "2017-05-15 10:10:22    1\n",
      "2017-05-15 10:10:23    1\n",
      "2017-05-15 10:10:24    1\n",
      "2017-05-15 10:10:25    1\n",
      "2017-05-15 10:10:26    1\n",
      "2017-05-15 10:10:27    1\n",
      "2017-05-15 10:10:28    1\n",
      "2017-05-15 10:10:29    1\n",
      "                      ..\n",
      "2017-08-14 14:27:30    1\n",
      "2017-08-14 14:27:31    1\n",
      "2017-08-14 14:27:32    1\n",
      "2017-08-14 14:27:33    1\n",
      "2017-08-14 14:27:34    1\n",
      "2017-08-14 14:27:35    1\n",
      "2017-08-14 14:27:36    1\n",
      "2017-08-14 14:27:37    1\n",
      "2017-08-14 14:27:38    1\n",
      "2017-08-14 14:27:39    1\n",
      "2017-08-14 14:27:40    1\n",
      "2017-08-14 14:27:41    1\n",
      "2017-08-14 14:27:42    1\n",
      "2017-08-14 14:27:43    1\n",
      "2017-08-14 14:27:44    1\n",
      "2017-08-14 14:27:45    1\n",
      "2017-08-14 14:27:46    1\n",
      "2017-08-14 14:27:47    1\n",
      "2017-08-14 14:27:48    1\n",
      "2017-08-14 14:27:49    1\n",
      "2017-08-14 14:27:50    1\n",
      "2017-08-14 14:27:51    1\n",
      "2017-08-14 14:27:52    1\n",
      "2017-08-14 14:27:53    1\n",
      "2017-08-14 14:27:54    1\n",
      "2017-08-14 14:27:55    1\n",
      "2017-08-14 14:27:56    1\n",
      "2017-08-14 14:27:57    1\n",
      "2017-08-14 14:27:58    1\n",
      "2017-08-14 14:27:59    1\n",
      "Length: 13420, dtype: int64"
     ]
    }
   ],
   "source": [
    "# Occurence of entries in the \"faulty\" telemetry stream over time\n",
    "\n",
    "# faulty_machine_sequence_pdf.apply(lambda x: 1, axis=1).plot(\n",
    "#     title='Telemetry stream of \"faulty\" machine {0}'.format(faultyMachineID), style='.', yticks=[])\n",
    "# plt.show()\n",
    "\n",
    "faulty_machine_sequence_pdf.apply(lambda x: 1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Telemetry frequency: 0 days 00:00:01"
     ]
    }
   ],
   "source": [
    "# Telemetry frequency\n",
    "# ('diffs' are computed by subtracting the previous timestamp\n",
    "# from the current one for each telemetry entry)\n",
    "\n",
    "diffs = faulty_machine_sequence_pdf.index.to_series().diff()\n",
    "mode_interval = diffs.mode()[0] # mode of the time intervals\n",
    "print('Telemetry frequency: {}'.format(mode_interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp\n",
      "2017-05-15 10:10:00            NaN\n",
      "2017-05-19 03:42:00    1048.016667\n",
      "2017-05-22 13:47:00     601.016667\n",
      "2017-05-23 01:01:00     670.016667\n",
      "2017-05-24 03:17:00     134.050000\n",
      "2017-05-25 04:40:00      81.016667\n",
      "2017-05-25 21:04:00     979.016667\n",
      "2017-05-26 21:20:00      14.016667\n",
      "2017-05-29 14:23:00    1022.016667\n",
      "2017-05-30 20:29:00     362.016667\n",
      "2017-05-31 11:25:00     895.016667\n",
      "2017-05-31 17:48:00     379.016667\n",
      "2017-06-01 20:56:00     183.016667\n",
      "2017-06-02 04:19:00     439.016667\n",
      "2017-06-02 06:50:00     149.016667\n",
      "2017-06-02 16:29:00     578.016667\n",
      "2017-06-02 17:16:00      44.016667\n",
      "2017-06-06 06:22:00     782.016667\n",
      "2017-06-06 21:06:00     879.016667\n",
      "2017-06-07 10:57:00     826.016667\n",
      "2017-06-08 22:56:00     718.016667\n",
      "2017-06-10 21:40:00    1361.016667\n",
      "2017-06-11 15:36:00    1071.016667\n",
      "2017-06-13 06:09:00     868.016667\n",
      "2017-06-15 01:59:00    1189.016667\n",
      "2017-06-15 10:17:00     497.016667\n",
      "2017-06-15 15:28:00     310.016667\n",
      "2017-06-16 14:45:00    1394.016667\n",
      "2017-06-16 16:32:00     105.016667\n",
      "2017-06-16 23:46:00     433.016667\n",
      "                          ...     \n",
      "2017-06-30 22:32:00     460.116667\n",
      "2017-07-01 03:38:00     304.016667\n",
      "2017-07-01 17:09:00     807.016667\n",
      "2017-07-02 23:05:00     351.016667\n",
      "2017-07-09 09:10:00     600.016667\n",
      "2017-07-10 23:50:00     878.016667\n",
      "2017-07-12 21:03:00    1272.016667\n",
      "2017-07-15 03:09:00     362.016667\n",
      "2017-07-16 19:49:00     997.016667\n",
      "2017-07-19 14:52:00    1139.016667\n",
      "2017-07-23 03:39:00     766.016667\n",
      "2017-07-24 03:28:00    1424.016667\n",
      "2017-07-25 02:04:00    1351.016667\n",
      "2017-07-25 06:27:00     258.016667\n",
      "2017-07-30 03:17:00    1245.016667\n",
      "2017-07-31 15:12:00     710.016667\n",
      "2017-08-01 20:41:00     328.016667\n",
      "2017-08-03 12:25:00     941.016667\n",
      "2017-08-06 01:03:00     754.366667\n",
      "2017-08-06 10:06:00     539.016667\n",
      "2017-08-07 13:31:00     202.016667\n",
      "2017-08-08 05:16:00     941.016667\n",
      "2017-08-08 18:00:00     763.016667\n",
      "2017-08-09 19:14:00      71.016667\n",
      "2017-08-10 14:57:00    1179.016667\n",
      "2017-08-11 05:19:00     859.016667\n",
      "2017-08-11 19:45:00     862.016667\n",
      "2017-08-11 22:52:00     183.016667\n",
      "2017-08-14 08:15:00     559.016667\n",
      "2017-08-14 14:24:00     367.016667\n",
      "Name: timestamp, Length: 72, dtype: float64"
     ]
    }
   ],
   "source": [
    "# Other, less common, intervals between telemetry entries (minutes)\n",
    "\n",
    "# gaps = diffs[diffs != mode_interval].dt.seconds/60\n",
    "# gaps.hist()\n",
    "# plt.title('telemetry frequency of \"faulty\" machine {}'.format(faultyMachineID))\n",
    "# plt.xlabel('Time [s]')\n",
    "# plt.ylabel('Count')\n",
    "# plt.show()\n",
    "\n",
    "diffs[diffs != mode_interval].dt.seconds/60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這表示機台循環運作後，有停滯的週期\n",
    "\n",
    "### 了解機台活動的循環／模式\n",
    "\n",
    "許多真實世界的機器以循環運作，一個循環可看作為時間上的週期，這可用來描述某個機台的運作狀態。例如：商用客機的渦輪風扇引擎，能被簡要的用循環描述：引擎運作（飛行時）或引擎停止（飛機著陸）。在此案例中，引擎被眼單的描述為引擎開關狀態，雖然非得這樣描述。在接下來的說明，我們將解釋為何將資料分為不同循環狀態，能有助於預測機台的情境\n",
    "\n",
    "## 建立特徵\n",
    "\n",
    "### 循環層級的資料聚合\n",
    "\n",
    "原始的遙測資料量，雖然對於實時監測和故障偵測至關重要，卻無直接被用來建立預測模型。因為通常假設在一個運作循環中，突發的衰退的可能性不高。通常的做法，是在每個運作時間單位內，產生一個聚合的測量值來描述資產的健康特性。運作時間單位通常是以小時或循環數表示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_cycles(df, min_gap = 30):\n",
    "    \"\"\"\n",
    "    Detects cycles and compresses them into \n",
    "    aggregate measurements.    \n",
    "    \n",
    "    :param DataFrame df: input Spark DataFrame\n",
    "    :param int min_gap: seconds between cycles (mininum)\n",
    "    \"\"\"\n",
    "    w = Window.partitionBy('machineID').orderBy('timestamp')\n",
    "\n",
    "    # Difference from the previous record or 0 if this is the first one\n",
    "    diff = F.coalesce(\n",
    "        F.unix_timestamp('timestamp') - F.unix_timestamp(\n",
    "            F.lag('timestamp', 1).over(w)\n",
    "        ), F.lit(0))\n",
    "\n",
    "    # 0 if diff <= 30, 1 otherwise\n",
    "    indicator = (diff > min_gap).cast('integer')\n",
    "\n",
    "    subgroup = F.sum(indicator).over(w).alias('cycle')\n",
    "\n",
    "    return df.select(\"*\", subgroup).groupBy('machineID', 'cycle').agg(\n",
    "        F.max('speed_desired').alias('speed_desired_max'),\n",
    "        F.avg('speed').alias('speed_avg'),\n",
    "        F.avg('temperature').alias('temperature_avg'),\n",
    "        F.max('temperature').alias('temperature_max'),\n",
    "        F.avg('pressure').alias('pressure_avg'),\n",
    "        F.max('pressure').alias('pressure_max'),\n",
    "        F.min('timestamp').alias('cycle_start'),\n",
    "        F.max('timestamp').alias('cycle_end')\n",
    "    ).orderBy('cycle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 在單一機台的資料集上測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    temperature_avg  temperature_max  pressure_avg  pressure_max\n",
      "0        142.232000           145.42   1321.448083       1452.26\n",
      "1        145.428167           145.63   1317.345417       1451.22\n",
      "2        145.642417           145.84   1316.304542       1449.43\n",
      "3        145.810593           145.95   1223.996525       1446.07\n",
      "4        145.910833           146.06   1202.359583       1446.14\n",
      "5        146.109400           146.34   1335.937167       1445.74\n",
      "6        146.320250           146.47   1199.993167       1443.10\n",
      "7        146.400833           146.53    975.036000       1442.22\n",
      "8        146.555250           146.77   1309.325458       1442.44\n",
      "9        146.719167           146.82    975.355167       1440.55\n",
      "10       146.872333           147.09   1307.604250       1440.00\n",
      "11       147.178067           147.42   1327.656600       1438.49\n",
      "12       147.490792           147.71   1305.361792       1436.75\n",
      "13       147.709500           147.87   1190.611250       1434.73\n",
      "14       147.819333           147.93    967.040333       1435.01\n",
      "15       147.976944           148.18   1264.938167       1434.77\n",
      "16       148.243250           148.50   1301.808208       1433.82\n",
      "17       148.622733           148.91   1322.926800       1432.89\n",
      "18       149.061700           149.38   1322.835133       1432.93\n",
      "19       149.342167           149.46    960.586000       1427.70\n",
      "20       149.540833           149.74   1262.883167       1433.14\n",
      "21       149.932433           150.26   1323.907367       1435.26\n",
      "22       150.468667           150.82   1327.585733       1440.16\n",
      "23       150.831167           150.95    963.726500       1440.15\n",
      "24       150.918833           151.07    967.210500       1440.06\n",
      "25       151.061333           151.21    970.668167       1444.57\n",
      "26       151.300222           151.56   1275.789556       1450.25\n",
      "27       151.631750           151.84   1202.325167       1455.25\n",
      "28       151.825667           151.97    975.609000       1457.99\n",
      "29       152.173167           152.52   1331.484292       1475.15\n",
      "..              ...              ...           ...           ...\n",
      "42       135.477000           135.58   1553.272250       1832.31\n",
      "43       135.505375           135.61   1686.454417       1839.00\n",
      "44       135.534233           135.64   1719.952733       1848.68\n",
      "45       135.562700           135.67   1730.060567       1858.56\n",
      "46       135.594917           135.69   1578.671750       1864.02\n",
      "47       135.594833           135.70   1314.426000       1867.43\n",
      "48       135.620750           135.73   1720.812750       1875.46\n",
      "49       135.642833           135.75   1685.491167       1886.82\n",
      "50       135.665875           135.78   1739.994208       1898.92\n",
      "51       135.689167           135.78   1343.421167       1902.73\n",
      "52       135.706467           135.81   1785.166000       1922.74\n",
      "53       135.735300           135.86   1805.977100       1947.77\n",
      "54       135.773900           135.88   1832.306200       1977.32\n",
      "55       135.814933           135.92   1867.593233       2019.13\n",
      "56       135.848500           135.96   1916.451133       2080.73\n",
      "57       135.873500           135.97   1478.154667       2098.82\n",
      "58       135.892889           135.99   1919.350833       2178.02\n",
      "59       135.911324           136.02   2271.511918       2700.50\n",
      "60       137.863958           137.99   1592.987333       2434.20\n",
      "61       137.904944           138.01   1527.441667       1714.79\n",
      "62       137.945458           138.07   1571.066875       1719.27\n",
      "63       137.970833           138.07   1192.011500       1720.90\n",
      "64       138.015722           138.12   1533.548722       1723.12\n",
      "65       138.056500           138.17   1579.905708       1729.35\n",
      "66       138.092667           138.21   1543.273944       1732.94\n",
      "67       138.139167           138.25   1589.339958       1738.42\n",
      "68       138.191542           138.31   1596.552875       1743.35\n",
      "69       138.243375           138.37   1599.289167       1752.02\n",
      "70       138.285083           138.39   1476.780167       1756.63\n",
      "71       138.318792           138.44   1610.935125       1763.97\n",
      "\n",
      "[72 rows x 4 columns]"
     ]
    }
   ],
   "source": [
    "machine_cycles_df = aggregate_cycles(faulty_machine_sequence_df)\n",
    "# machine_cycles_df[['temperature_avg',\n",
    "#              'temperature_max',\n",
    "#              'pressure_avg',\n",
    "#              'pressure_max']].toPandas().plot(subplots=True,\n",
    "#                                               title='Cycle-level measurements of \"faulty\" machine {}'.format(faultyMachineID))\n",
    "# plt.xlabel('Cycles')\n",
    "# plt.show()\n",
    "\n",
    "machine_cycles_df[['temperature_avg',\n",
    "             'temperature_max',\n",
    "             'pressure_avg',\n",
    "             'pressure_max']].toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "為了比較，這裡展示 **健康** 機器的循環級別測量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    temperature_avg  temperature_max  pressure_avg  pressure_max\n",
      "0        120.626833           136.61   1065.785833       1525.05\n",
      "1        136.512167           136.61   1063.700833       1520.28\n",
      "2        136.548458           136.65   1397.339292       1527.57\n",
      "3        136.586667           136.69   1398.044208       1526.54\n",
      "4        136.611867           136.73   1418.521333       1525.91\n",
      "5        136.660444           136.76   1357.716111       1524.16\n",
      "6        136.686944           136.78   1357.656167       1523.18\n",
      "7        136.687500           136.80   1062.720333       1519.62\n",
      "8        136.718500           136.81   1061.098500       1521.45\n",
      "9        136.722000           136.82   1282.484333       1522.50\n",
      "10       136.757933           136.87   1414.681000       1521.92\n",
      "11       136.793833           136.90   1352.931278       1520.63\n",
      "12       136.821944           136.93   1352.881778       1519.99\n",
      "13       136.849611           136.95   1352.821667       1519.08\n",
      "14       136.875750           136.99   1389.264750       1518.39\n",
      "15       136.912056           137.02   1349.196111       1516.91\n",
      "16       136.935833           137.04   1278.534833       1516.41\n",
      "17       136.968633           137.08   1406.988133       1515.95\n",
      "18       137.004000           137.10   1054.595167       1513.47\n",
      "19       137.011000           137.11   1052.899000       1513.99\n",
      "20       137.028083           137.13   1275.063583       1513.04\n",
      "21       137.053833           137.16   1347.168444       1512.92\n",
      "22       137.078417           137.18   1271.341667       1512.72\n",
      "23       137.073833           137.19   1053.070833       1512.26\n",
      "24       137.127833           137.24   1404.377367       1511.77\n",
      "25       137.148333           137.25   1051.044333       1508.55\n",
      "26       137.184625           137.30   1381.331958       1510.09\n",
      "27       137.208000           137.31   1048.801833       1506.47\n",
      "28       137.206500           137.30   1049.636833       1508.60\n",
      "29       137.227444           137.34   1343.458111       1508.79\n",
      "..              ...              ...           ...           ...\n",
      "42       137.729542           137.85   1365.036417       1494.82\n",
      "43       137.774389           137.89   1328.300889       1493.74\n",
      "44       137.811667           137.91   1253.605167       1492.73\n",
      "45       137.834333           137.92   1034.152000       1488.41\n",
      "46       137.858708           137.97   1361.928958       1491.70\n",
      "47       137.879167           137.98   1033.876833       1490.71\n",
      "48       137.900833           138.00   1034.749000       1484.25\n",
      "49       137.921500           138.01   1033.241500       1489.46\n",
      "50       137.932167           138.03   1249.218583       1488.05\n",
      "51       137.948000           138.05   1248.998000       1488.68\n",
      "52       137.974500           138.08   1250.595917       1487.98\n",
      "53       138.011708           138.13   1358.412958       1486.74\n",
      "54       138.052500           138.17   1322.219500       1485.51\n",
      "55       138.099750           138.22   1354.959542       1484.74\n",
      "56       138.138417           138.24   1244.470500       1483.79\n",
      "57       138.173222           138.29   1317.661278       1482.84\n",
      "58       138.214278           138.32   1316.072167       1481.40\n",
      "59       138.265200           138.39   1372.894300       1480.34\n",
      "60       138.330467           138.45   1371.813400       1478.25\n",
      "61       138.364833           138.47   1023.238833       1477.06\n",
      "62       138.409667           138.53   1369.871300       1476.59\n",
      "63       138.469333           138.58   1345.351375       1474.87\n",
      "64       138.538900           138.67   1365.961367       1473.32\n",
      "65       138.573000           138.68   1013.023500       1470.31\n",
      "66       138.605000           138.72   1305.655611       1471.30\n",
      "67       138.659267           138.79   1361.803933       1469.61\n",
      "68       138.740833           138.86   1359.743833       1468.13\n",
      "69       138.773000           138.88   1011.480667       1465.92\n",
      "70       138.815500           138.92   1300.141278       1465.00\n",
      "71       138.839000           138.94   1011.045667       1463.56\n",
      "\n",
      "[72 rows x 4 columns]"
     ]
    }
   ],
   "source": [
    "machine_cycles_df = aggregate_cycles(healthy_machine_sequence_df)\n",
    "# machine_cycles_df[['temperature_avg',\n",
    "#              'temperature_max',\n",
    "#              'pressure_avg',\n",
    "#              'pressure_max']].toPandas().plot(subplots=True,\n",
    "#                                               title='Cycle-level measurements of \"healthy\" machine {}'.format(healthyMachineID))\n",
    "# plt.xlabel('Cycles')\n",
    "# plt.show()\n",
    "\n",
    "machine_cycles_df[['temperature_avg',\n",
    "             'temperature_max',\n",
    "             'pressure_avg',\n",
    "             'pressure_max']].toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 對整個資料及進行轉換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 72563 cycle(s)"
     ]
    }
   ],
   "source": [
    "cycles_df = aggregate_cycles(telemetry_input_df)\n",
    "print('Total: {0} cycle(s)'.format(cycles_df.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 標註\n",
    "\n",
    "在日誌中，故障事件前的機台循環能根據在序列的位置，而被視為「剩餘有用生命 (RUL) 」標註。例如，在一個故障前的循環能被設為 RUL=1，且其之前的循環可設為 RUL=2，依此類推\n",
    "\n",
    "RUL 能以如下方式轉換為多類別標註：\n",
    "\n",
    "$$\n",
    "L_i = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "      F_i & rul_i\\leq w \\\\\n",
    "      \\emptyset & \\text{otherwise} \\\\\n",
    "\\end{array} \n",
    "\\right.\n",
    "$$\n",
    "\n",
    "其中 $F_i$ 是某類結束運作循環序列的故障；$rul_i$ 是 RUL 值，$w$ 是未來的水平"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating failure intervals\n",
    "\n",
    "w = Window.partitionBy('machineID', 'level').orderBy('timestamp')\n",
    "# the period between consequtive failures,\n",
    "# or \"since the beginning of time\" if no previous failure record is on file\n",
    "diff = F.coalesce(F.lag('timestamp', 1).over(w), F.to_timestamp(F.lit('2000-01-01 00:00:00')))\n",
    "\n",
    "failure_intervals_df = (failures_df\n",
    "                .withColumn('last_failure_timestamp', diff)\n",
    "                .withColumnRenamed('timestamp', 'failure_timestamp')\n",
    "                .withColumnRenamed('code', 'upcoming_failure')\n",
    "                .drop('level'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 所選機台的故障間隔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    failure_timestamp          ...           last_failure_timestamp\n",
      "0 2017-06-22 03:56:09          ...              2000-01-01 00:00:00\n",
      "1 2017-08-03 12:28:39          ...              2017-06-22 03:56:09\n",
      "\n",
      "[2 rows x 4 columns]"
     ]
    }
   ],
   "source": [
    "machine_failure_intervals_df = failure_intervals_df.where(\n",
    "    F.col('machineID') == faultyMachineID)\n",
    "machine_failure_intervals_df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 給所有循環標註\n",
    "\n",
    "此外，為每個運作直到故障的循環序列，以及沒有發生故障的循環序列，都生成一個獨一的 ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 7 # future horizon (cycles)\n",
    "\n",
    "labeled_cycles_df = (\n",
    "    cycles_df.join(failure_intervals_df,\n",
    "                   (cycles_df.machineID == failure_intervals_df.machineID) &\n",
    "                   (cycles_df.cycle_start >= failure_intervals_df.last_failure_timestamp) &\n",
    "                   (cycles_df.cycle_end <= failure_intervals_df.failure_timestamp),\n",
    "                   'left_outer')\n",
    "    .drop(failure_intervals_df.machineID)\n",
    "    .drop(cycles_df.cycle_end)\n",
    "    .drop(failure_intervals_df.last_failure_timestamp)\n",
    "    .withColumnRenamed('cycle_start', 'timestamp')\n",
    "    .withColumn(\n",
    "     'rul',                         \n",
    "      F.when(F.col('upcoming_failure').isNull(), None).otherwise(\n",
    "         F.row_number().over(Window.partitionBy('machineID', 'failure_timestamp')\n",
    "                         .orderBy(F.desc('cycle')))))\n",
    "    .withColumn(\n",
    "     'sequenceID',\n",
    "     F.dense_rank().over(Window.partitionBy('machineID')\n",
    "                   .orderBy(F.desc('upcoming_failure'), 'failure_timestamp')))\n",
    "    .drop(failure_intervals_df.failure_timestamp)\n",
    "    .withColumn('immediate_failure',\n",
    "                F.when(F.col('rul').isNotNull() & (F.col('rul') < w),\n",
    "                       F.col('upcoming_failure'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 所選機台的故障間隔與序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     sequenceID upcoming_failure\n",
      "timestamp                                       \n",
      "2017-05-15 10:10:00           1               F2\n",
      "2017-05-22 13:47:00           1               F2\n",
      "2017-05-25 21:04:00           1               F2\n",
      "2017-05-26 21:20:00           1               F2\n",
      "2017-05-31 11:25:00           1               F2\n",
      "2017-05-31 17:48:00           1               F2\n",
      "2017-06-02 04:19:00           1               F2\n",
      "2017-06-02 06:50:00           1               F2\n",
      "2017-06-06 06:22:00           1               F2\n",
      "2017-06-06 21:06:00           1               F2\n",
      "2017-06-10 21:40:00           1               F2\n",
      "2017-06-11 15:36:00           1               F2\n",
      "2017-06-15 10:17:00           1               F2\n",
      "2017-06-15 15:28:00           1               F2\n",
      "2017-06-18 23:26:00           1               F2\n",
      "2017-06-21 00:46:00           1               F2\n",
      "2017-06-21 22:23:00           1               F2\n",
      "2017-06-22 03:56:00           1               F2\n",
      "2017-05-19 03:42:00           1               F2\n",
      "2017-05-23 01:01:00           1               F2\n",
      "2017-05-24 03:17:00           1               F2\n",
      "2017-05-25 04:40:00           1               F2\n",
      "2017-05-29 14:23:00           1               F2\n",
      "2017-05-30 20:29:00           1               F2\n",
      "2017-06-01 20:56:00           1               F2\n",
      "2017-06-02 16:29:00           1               F2\n",
      "2017-06-02 17:16:00           1               F2\n",
      "2017-06-07 10:57:00           1               F2\n",
      "2017-06-08 22:56:00           1               F2\n",
      "2017-06-13 06:09:00           1               F2\n",
      "...                         ...              ...\n",
      "2017-07-25 02:04:00           2               F2\n",
      "2017-07-25 06:27:00           2               F2\n",
      "2017-07-31 15:12:00           2               F2\n",
      "2017-08-03 12:25:00           2               F2\n",
      "2017-06-23 06:14:00           2               F2\n",
      "2017-06-26 18:22:00           2               F2\n",
      "2017-06-27 04:31:00           2               F2\n",
      "2017-06-27 16:11:00           2               F2\n",
      "2017-06-30 22:32:00           2               F2\n",
      "2017-07-01 03:38:00           2               F2\n",
      "2017-07-09 09:10:00           2               F2\n",
      "2017-07-12 21:03:00           2               F2\n",
      "2017-07-15 03:09:00           2               F2\n",
      "2017-07-19 14:52:00           2               F2\n",
      "2017-07-23 03:39:00           2               F2\n",
      "2017-07-24 03:28:00           2               F2\n",
      "2017-07-30 03:17:00           2               F2\n",
      "2017-08-01 20:41:00           2               F2\n",
      "2017-08-06 10:06:00           3             None\n",
      "2017-08-08 05:16:00           3             None\n",
      "2017-08-09 19:14:00           3             None\n",
      "2017-08-11 05:19:00           3             None\n",
      "2017-08-11 22:52:00           3             None\n",
      "2017-08-14 14:24:00           3             None\n",
      "2017-08-06 01:03:00           3             None\n",
      "2017-08-07 13:31:00           3             None\n",
      "2017-08-08 18:00:00           3             None\n",
      "2017-08-10 14:57:00           3             None\n",
      "2017-08-11 19:45:00           3             None\n",
      "2017-08-14 08:15:00           3             None\n",
      "\n",
      "[72 rows x 2 columns]"
     ]
    }
   ],
   "source": [
    "machine_labeled_cycles_df = labeled_cycles_df.where(\n",
    "    F.col('machineID') == faultyMachineID\n",
    ").select('timestamp', 'sequenceID', 'upcoming_failure')\n",
    "\n",
    "max_sequence_id = machine_labeled_cycles_df.select(\n",
    "    F.max('sequenceID')).collect()[0][0]\n",
    "# machine_labeled_cycles_df.toPandas().set_index('timestamp').plot(\n",
    "#     style='.', yticks=range(1, max_sequence_id + 1))\n",
    "# plt.ylabel('Sequence')\n",
    "# plt.show()\n",
    "\n",
    "machine_labeled_cycles_df.toPandas().set_index('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- machineID: string (nullable = true)\n",
      " |-- cycle: long (nullable = true)\n",
      " |-- speed_desired_max: long (nullable = true)\n",
      " |-- speed_avg: double (nullable = true)\n",
      " |-- temperature_avg: double (nullable = true)\n",
      " |-- temperature_max: double (nullable = true)\n",
      " |-- pressure_avg: double (nullable = true)\n",
      " |-- pressure_max: double (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- upcoming_failure: string (nullable = true)\n",
      " |-- rul: integer (nullable = true)\n",
      " |-- sequenceID: integer (nullable = true)\n",
      " |-- immediate_failure: string (nullable = true)"
     ]
    }
   ],
   "source": [
    "# Labeled data set\n",
    "labeled_cycles_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用時序上延遲的特徵擴增資料\n",
    "\n",
    "為了幫助描繪每台機器短期的趨勢，通常會用新的特徵擴增原有的資料集 [[3]](#ref_3)，這些特徵是通過滑動時間窗的方式計算的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- machineID: string (nullable = true)\n",
      " |-- cycle: long (nullable = true)\n",
      " |-- speed_desired_max: long (nullable = true)\n",
      " |-- speed_avg: double (nullable = true)\n",
      " |-- temperature_avg: double (nullable = true)\n",
      " |-- temperature_max: double (nullable = true)\n",
      " |-- pressure_avg: double (nullable = true)\n",
      " |-- pressure_max: double (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- upcoming_failure: string (nullable = true)\n",
      " |-- rul: integer (nullable = true)\n",
      " |-- sequenceID: integer (nullable = true)\n",
      " |-- immediate_failure: string (nullable = true)\n",
      " |-- temperature_avg_avg: double (nullable = true)\n",
      " |-- temperature_max_avg: double (nullable = true)\n",
      " |-- pressure_avg_avg: double (nullable = true)\n",
      " |-- pressure_max_avg: double (nullable = true)"
     ]
    }
   ],
   "source": [
    "# TODO: compute more rolling features\n",
    "# (e.g., linear regression, standard deviation)\n",
    "\n",
    "lookback = 5\n",
    "w = Window.partitionBy(\n",
    "    'machineID', 'sequenceID'\n",
    ").rowsBetween(-lookback, Window.currentRow).orderBy('cycle')\n",
    "\n",
    "# computing rolling averages for these cycle-level features\n",
    "input_columns = ['temperature_avg', 'temperature_max', 'pressure_avg', 'pressure_max']\n",
    "\n",
    "# adding rolling features and eliminating the entries in the beginning of each\n",
    "# sequence which weren't computed using a sufficient number of previous values\n",
    "augmented_labeled_cycles_df = (\n",
    "    reduce(lambda _df, ic: _df.withColumn(\n",
    "        '{0}_avg'.format(ic), F.avg(ic).over(w)), input_columns, labeled_cycles_df)\n",
    "    .withColumn('is_valid', F.count(F.lit(1)).over(w) > lookback)\n",
    "    .where(F.col('is_valid'))\n",
    "    .drop('is_valid'))\n",
    "\n",
    "augmented_labeled_cycles_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保留未來使用的資料集\n",
    "\n",
    "\n",
    "考慮到一般性，所有特定類別的特徵名稱會模糊化，且明確的時間戳記會被替換為時間 ID 以表示相對的時間順序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- machineID: string (nullable = true)\n",
      " |-- cycle: long (nullable = true)\n",
      " |-- s1: long (nullable = true)\n",
      " |-- s2: double (nullable = true)\n",
      " |-- s3: double (nullable = true)\n",
      " |-- s4: double (nullable = true)\n",
      " |-- s5: double (nullable = true)\n",
      " |-- s6: double (nullable = true)\n",
      " |-- rul: integer (nullable = true)\n",
      " |-- sequenceID: integer (nullable = true)\n",
      " |-- immediate_failure: string (nullable = true)\n",
      " |-- s7: double (nullable = true)\n",
      " |-- s8: double (nullable = true)\n",
      " |-- s9: double (nullable = true)\n",
      " |-- s10: double (nullable = true)\n",
      " |-- entryID: integer (nullable = true)"
     ]
    }
   ],
   "source": [
    "feature_columns = [\n",
    "    c for c in augmented_labeled_cycles_df.columns if c not in (\n",
    "        'machineID', 'cycle', 'sequenceID', 'rul', 'upcoming_failure', 'immediate_failure', 'timestamp')]\n",
    "obfuscate_columns = zip(feature_columns, range(1, len(feature_columns) + 1))\n",
    "\n",
    "feature_df = reduce(lambda _df, ic: _df.withColumnRenamed(ic[0], 's{0}'.format(ic[1])),\n",
    "    obfuscate_columns, augmented_labeled_cycles_df).withColumn(\n",
    "    'entryID', F.row_number().over(Window().orderBy('timestamp'))\n",
    ").drop('upcoming_failure', 'timestamp')\n",
    "\n",
    "feature_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = 5 # split the data into N chunks\n",
    "feature_df.coalesce(chunks).write.csv(data_root_dir + '/model/features',mode=\"overwrite\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "https://www.youtube.com/watch?v=drUToKxEAUA\n",
    "\n",
    "http://waset.org/publications/10006640/building-a-scalable-telemetry-based-multiclass-predictive-maintenance-model-in-r\n",
    "\n",
    "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.386.8108&rep=rep1&type=pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
